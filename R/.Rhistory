TRUE==TRUE
(FALSE == TRUE) == FALSE
6==7
6 < 7
10 <= 10
5 != 7
!False
!FALSE
swirl()
my_vector c(1:20)
my_vector <- c(1:20)
my_vector <- c(1:20)
my_vector <- 1:20
swirl()
swirl()
5  != 7
!(5 == 7)
F & F
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
T <- F
T == FALSE
rm(T)
swirl()
TRUE |
c(TRUE, FALSE, FALSE).
TRUE | c(TRUE, FALSE, FALSE).
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
swirl()
library(Hmisc)
attach(titanic3)
attach(titanic3)
library(dplyr)
.
getwd()
;
people <- read.csv("people.csv")
people
people <- read.csv("people.csv")
submissions <- read.csv("swpcsubmissions.csv")
library(dplyr)
?join
View(submissions)
names(submissions)
names(people)
joined <- inner_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
View(joined)
View(submissions)
library(dplyr)
people <- read.csv("people.csv")
submissions <- read.csv("swpcsubmissions.csv")
joined <- inner_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
people$DomainAddress <- toUpper(people$DomainAddress)
people$DomainAddress <- toupper(people$DomainAddress)
submissions$Primary.Author <- toupper(submissions$Primary.Author)
joined <- inner_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
joined <- left_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
joined <- right_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
View(joined)
filter(joined, is.na(title))
filter(joined, title = "SA")
filter(joined, title == "SA")
?filter
?filter
View(joined)
filter(joined, Title == "SA")
library(dplyr)
filter(joined, Title == "SA")
View(joined)
filter(joined, Title == "YIELD ENGINEER")
filter(joined, WWID == 11341136)
filter(joined, is.na(WWID))
filter(joined, is.na(WWID)) %>% select(Primary.Author)
filter(joined, is.na(WWID)) %>% select(DomainAddress)
filter(submissions, is.na(Primary.Author))
filter(submissions, Primary.Author == "WALTER.D.VERME@INTEL.COM")
write.csv(joined, "SWPCcompleteInfo.csv")
?write.csv
write.csv(joined, "SWPCcompleteInfo.csv")
Titanic
Titanic[1]
Titanic[2]
mosaicplot(Titanic, main = "Survival on the Titanic")
library(help = "datasets").
library(help = "datasets")
USPersonalExpenditure
quakes
swiss
beavers
beavers
cars
WorldPhones
Loblolly
ToothGrowth
coplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth,
xlab = "ToothGrowth data: length vs dose, given type of supplement")
HairEyeColor
crimtab
morley
sleep
datasets-package
Titanic
Formaldehyde
Nile
Loblolly
swiss
class(swiss)
stripchart(swiss$Fertility)
stripchart(swiss$Infant.Mortality)
stripchart(swiss$Infant.Mortality,method="jitter")
?swiss
pairs(swiss, panel = panel.smooth, main = "swiss data",
col = 3 + (swiss$Catholic > 50))
?hist
hist(swiss$Fertility)
hist(swiss$Education)
mean(swiss$Education)
summary(swiss$Education)
hist(swiss$Education, breaks = 5)
hist(swiss$Education, breaks = 5)
hist(swiss$Education, breaks = 4)
hist(swiss$Education,breaks=2)
hist(swiss$Education,breaks=2)
hist(swiss$Education,breaks=10)
?hist
?swiss
hist(swiss$Education,breaks=10, main='Swiss education histogram',
xlab='% Infant.Mortality   live births who live less than 1 year')
hist(swiss$Education)
?swiss
stripchart(swiss$Fertility)
stripchart(swiss$Fertility,method="jitter")
stripchart(swiss$Fertility,method="jitter", main='Fertility in the swiss database',
xlab='Fertility in LG'
)
hist(swiss$Education)
summary(swiss$Education)
mean(swiss$Education)
hist(swiss$Education,breaks=10, main='Swiss education histogram',
xlab='% Infant.Mortality   live births who live less than 1 year')
boxplot(swiss$Education)
boxplot(swiss$Fertility, main='Fertility in the swiss database',
xlab='Fertility in LG')
plot(swiss$Fertility, swiss$Education)
cor(swiss$Fertility, swiss$Education)
swiss
plot(swiss$Fertility, swiss$Infant.Mortality)
cor(swiss$Fertility, swiss$Infant.Mortality)
plot(swiss$Fertility, swiss$Agriculture)
cor(swiss$Fertility, swiss$Agriculture)
plot(swiss$Fertility, swiss$Examination)
cor(swiss$Fertility, swiss$Examination)
plot(swiss$Fertility, swiss$Education)
cor(swiss$Fertility, swiss$Education)
plot(swiss$Fertility, swiss$Catholic)
cor(swiss$Fertility, swiss$Catholic)
plot(swiss$Fertility, swiss$Infant.Mortality)
cor(swiss$Fertility, swiss$Infant.Mortality)
qqnorm(swiss$Fertility)
??qqnorm
qqnorm(swiss$Fertility)
qqline(swiss$Fertility)
?qqnorm
plot(swiss$Fertility, swiss$Examination)
cor(swiss$Fertility, swiss$Examination)
temp <- swiss[swiss$Education > 0.75, swiss$Examination > 0.75]
temp <- swiss[swiss$Education > 0.75, swiss$Examination > 0.75,]
temp <- swiss[swiss$Education > 0.75 & swiss$Examination > 0.75,]
summary(temp$fertility)
summary(temp)
?discretize
discretize
library(arules)
install.packages(arules)
cut(swiss$Fertility, c(0,0.25,0.5,0.75,1))
cut(swiss$Education, c(0,0.25,0.5,0.75,1))
swiss$Education
cut(swiss$Education, c(0,25,50,75,100))
swiss$EducationCategorical <- cut(swiss$Education, c(0,25,50,75,100))
swiss$EducationCategorical
swiss[swiss$EducationCategorical  == "(75,100]"]
swiss$EducationCategorical[1]
swiss$EducationCategorical == "(75,100]"
swiss$EducationCategorical == 1
fileInput<- "C:\Users\rmongemo\Desktop\SampleEDWData\channel ops 201409.csv"
dataFrame <- read.csv(fileInput)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201409.csv"
dataFrame <- read.csv(fileInput)
?read.csv
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = "~", quote = "", header=T)
View(frame)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = "~", quote = "", header=T)
frame <- read.csv(fileInput, sep = "~", header=T)
quote = ""
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = ",", quote = "", header=T)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = ",", quote = "", header=T)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = ",", quote = "\"", header=T)
data()
data(airquality)
data(airquality)
airquality
plot(Ozone~Solor.R, data=airquality)
plot(Ozone~Solar.R, data=airquality)
2+2
data(mtcars)
n <- length(mtcars$mpg)
alpha <- 0.05
fit <- lm(mpg ~ am, data = mtcars)
coef(summary(fit))
sat<- read.csv("Sat.csv")
library(dplyr)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
set.seed(125)
set.seed(125)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
inTraining <- createDataPartition(y=spam$Case,list=FALSE)
inTraining <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
set.seed(125)
inTraining <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTraining
]
testing  <- segmentationOriginal[-inTraining]
modFit <- train(Case ~ .,method="rpart",data=training)
modFit <- train(Case ~ .,method="rpart",data=training)
modFit <- train(Case ~ .,method="rpart",data=training)
library(caret)
modFit <- train(Case ~ .,method="rpart",data=training)
?train
modFit <- train(Case ~ . ,method="rpart",data=training)
modFit <- train(Case ~ . ,method="rpart", data=training)
modFit <- train(form= Case ~ . ,method="rpart", data=training)
data(iris);
library(ggplot2)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species ~ .,method="rpart",data=training)
data(segmentationOriginal)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
set.seed(125)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
prediction <- predict(modFit,newdata=testing)
print(modFit)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,      main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
View(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Class,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Class ~ .,method="rpart",data=training)
prediction <- predict(modFit,newdata=testing)
plot(modFit$finalModel, uniform=TRUE,      main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
4.726e+04
library(dplyr)
training <- filter(segmentationOriginal, Case == "Train")
training <- filter(segmentationOriginal, Case == "Train")
testing <- filter(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ .,method="rpart",data=training)
library(rpart)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(rpart.plot)
install.packages(rpart.plot)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
View(olive)
modFit <- train(Area ~ .,method="rpart",data=olive)
library(rattle)
library(rpart.plot)
library(caret)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit,newdata=newdata)
View(olive)
library(ElemStatLearn)
install.packages("ElemStatLearn")
?train
library(ElemStatLearn)
library(rattle)
library(rpart.plot)
library(caret)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modFit <- train(Area ~ .,method="glm",data=train, family = "binomial")
View(SAheart)
str(SAheart)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea+ ldl,method="glm",data=trainSA, family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predictResult <- predict(modFit,newdata=testSA)
predictTrain <- predict(modFit,newdata=trainSA)
predictTest <- predict(modFit,newdata=testSA)
missClass(trainSA$chd, predictTrain)
missClass(testSa$chd, predictTest) $ 0.27
missClass(testSa$chd, predictTest)
missClass(testSA$chd, predictTest) # 0.27
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
vowel.test
View(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
?varImp
varImp(modFit)
install.packages("twitteR")
install.packages("streamR")
install.packages("ROAuth")
commonTermsDf
names(commonTermsDf)
library(twitteR)
library(RCurl)
library(base64enc)
library(httr)
library(tm)
library(ggplot2)
library(SnowballC)
library(reshape2)
library(sentiment)
library(fpc)
library(cluster)
library(dplyr)
library(tm)
source("GetTweets.R")
source("BuildCorpus.R")
source("keywordChart.R")
source("Clusters.R")
source("Sentiment.R")
tweets <- GetTweetsFromFile()
corpus <- BuildCorpus(tweets)
# build a term-document matrix
termsMatrix <- TermDocumentMatrix(corpus)
# inspect most popular words
#findFreqTerms(termsMatrix, lowfreq=300)
obamaChart <- GetKeywordChart("obama", termsMatrix)
plot(obamaChart)
## keep only the top words
commonTermsMatrix <- removeSparseTerms(termsMatrix, sparse=0.98)
commonTermsDf <- as.data.frame(inspect(commonTermsMatrix))
source("GetTweets.R")
source("BuildCorpus.R")
source("keywordChart.R")
source("Clusters.R")
source("Sentiment.R")
getwd()
setwd("C:/rafamonge/Twitter/R")
source("GetTweets.R")
source("BuildCorpus.R")
source("keywordChart.R")
source("Clusters.R")
source("Sentiment.R")
tweets <- GetTweetsFromFile()
corpus <- BuildCorpus(tweets)
# build a term-document matrix
termsMatrix <- TermDocumentMatrix(corpus)
# inspect most popular words
#findFreqTerms(termsMatrix, lowfreq=300)
obamaChart <- GetKeywordChart("obama", termsMatrix)
plot(obamaChart)
## keep only the top words
commonTermsMatrix <- removeSparseTerms(termsMatrix, sparse=0.98)
commonTermsDf <- as.data.frame(inspect(commonTermsMatrix))
commonTermsDf[1:4, 1:5]
commonTermsDf[!rownames(commonTermsDf) %in% 'intel']
commonTermsDf <- commonTermsDf[!rownames(commonTermsDf) %in% 'intel']
## H Cluster
fit < GetHClust(commonTermsDf)
#groups <- cutree(fit, k=5) # cut tree into 5 clusters
plot(fit) # display dendogram?
rect.hclust(fit, k=5, border="red")
fit
fit < GetHClust(commonTermsDf)
fit <- GetHClust(commonTermsDf)
plot(fit) # display dendogram?
rect.hclust(fit, k=5, border="red")
rownames(commonTermsDf
)
commonTermsDf <- commonTermsDf[!rownames(commonTermsDf) %in% c('intel')]
rownames(commonTermsDf
)
## H Cluster
fit <- GetHClust(commonTermsDf)
#groups <- cutree(fit, k=5) # cut tree into 5 clusters
plot(fit) # display dendogram?
rect.hclust(fit, k=5, border="red")
commonTermsDf <- commonTermsDf[!rownames(commonTermsDf) %in% c('intel')]
rownames(commonTermsDf
)
commonTermsDf <- as.data.frame(inspect(commonTermsMatrix))
commonTermsDf <- commonTermsDf[!rownames(commonTermsDf) %in% c('intel'),]
rownames(commonTermsDf)
## H Cluster
fit <- GetHClust(commonTermsDf)
#groups <- cutree(fit, k=5) # cut tree into 5 clusters
plot(fit) # display dendogram?
rect.hclust(fit, k=5, border="red")
kfit <- GetKMeans(commonTermsDf,6)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
#clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
source("Clusters.R")
kfit <- GetKMeans(commonTermsDf,6,d)
d <- dist(commonTermsDf.scale, method = "euclidean") # distance matrix
d <- dist(commonTermsDf.scale, method = "euclidean") # distance matrix
d <- dist(commonTermsDf.scale, method = "euclidean") # distance matrix
commonTermsDf.scale <- scale(commonTerms)
## H Cluster
d <- dist(commonTermsDf.scale, method = "euclidean") # distance matrix
commonTermsDf.scale <- scale(commonTermsDf)
## H Cluster
d <- dist(commonTermsDf.scale, method = "euclidean") # distance matrix
fit <- GetHClust(commonTermsDf, d)
plot(fit) # display dendogram?
rect.hclust(fit, k=5, border="red")
plot(fit) # display dendogram?
rect.hclust(fit, k=5, border="red")
kfit <- GetKMeans(commonTermsDf,6,d)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
head(commonTermsDf)
tweets <- GetTweetsFromFile()
corpus <- BuildCorpus(tweets)
# build a term-document matrix
termsMatrix <- TermDocumentMatrix(corpus)
library(twitteR)
library(RCurl)
library(base64enc)
library(httr)
library(tm)
library(ggplot2)
library(SnowballC)
library(reshape2)
library(sentiment)
library(fpc)
library(cluster)
library(dplyr)
library(tm)
source("GetTweets.R")
source("BuildCorpus.R")
source("keywordChart.R")
source("Clusters.R")
source("Sentiment.R")
tweets <- GetTweetsFromFile()
corpus <- BuildCorpus(tweets)
# build a term-document matrix
termsMatrix <- TermDocumentMatrix(corpus)
commonTermsMatrix <- removeSparseTerms(termsMatrix, sparse=0.98)
commonTermsDf <- as.data.frame(inspect(commonTermsMatrix))
commonTermsDf <- commonTermsDf[!rownames(commonTermsDf) %in% c('intel'),]
head(commonTermsDf)
rownames(commonTermsDf)
rowcols(commonTermsDf)
colnames(commonTermsDf)
commonTermsDf[1:5, 2]
commonTermsDf[1:5, 1]
