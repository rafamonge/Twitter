as.factor(paste(as.chraracter(fact), as.character(fact2),sep="-"))
as.factor(paste(as.character(fact), as.character(fact2),sep="-"))
library(swirl)
swirl()
T==T
True==True
TRUE==TRUE
(FALSE == TRUE) == FALSE
6==7
6 < 7
10 <= 10
5 != 7
!False
!FALSE
swirl()
my_vector c(1:20)
my_vector <- c(1:20)
my_vector <- c(1:20)
my_vector <- 1:20
swirl()
swirl()
5  != 7
!(5 == 7)
F & F
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
T <- F
T == FALSE
rm(T)
swirl()
TRUE |
c(TRUE, FALSE, FALSE).
TRUE | c(TRUE, FALSE, FALSE).
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
swirl()
library(Hmisc)
attach(titanic3)
attach(titanic3)
library(dplyr)
.
getwd()
;
people <- read.csv("people.csv")
people
people <- read.csv("people.csv")
submissions <- read.csv("swpcsubmissions.csv")
library(dplyr)
?join
View(submissions)
names(submissions)
names(people)
joined <- inner_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
View(joined)
View(submissions)
library(dplyr)
people <- read.csv("people.csv")
submissions <- read.csv("swpcsubmissions.csv")
joined <- inner_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
people$DomainAddress <- toUpper(people$DomainAddress)
people$DomainAddress <- toupper(people$DomainAddress)
submissions$Primary.Author <- toupper(submissions$Primary.Author)
joined <- inner_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
joined <- left_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
joined <- right_join (people, submissions, by = c("DomainAddress" = "Primary.Author" ))
View(joined)
filter(joined, is.na(title))
filter(joined, title = "SA")
filter(joined, title == "SA")
?filter
?filter
View(joined)
filter(joined, Title == "SA")
library(dplyr)
filter(joined, Title == "SA")
View(joined)
filter(joined, Title == "YIELD ENGINEER")
filter(joined, WWID == 11341136)
filter(joined, is.na(WWID))
filter(joined, is.na(WWID)) %>% select(Primary.Author)
filter(joined, is.na(WWID)) %>% select(DomainAddress)
filter(submissions, is.na(Primary.Author))
filter(submissions, Primary.Author == "WALTER.D.VERME@INTEL.COM")
write.csv(joined, "SWPCcompleteInfo.csv")
?write.csv
write.csv(joined, "SWPCcompleteInfo.csv")
Titanic
Titanic[1]
Titanic[2]
mosaicplot(Titanic, main = "Survival on the Titanic")
library(help = "datasets").
library(help = "datasets")
USPersonalExpenditure
quakes
swiss
beavers
beavers
cars
WorldPhones
Loblolly
ToothGrowth
coplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth,
xlab = "ToothGrowth data: length vs dose, given type of supplement")
HairEyeColor
crimtab
morley
sleep
datasets-package
Titanic
Formaldehyde
Nile
Loblolly
swiss
class(swiss)
stripchart(swiss$Fertility)
stripchart(swiss$Infant.Mortality)
stripchart(swiss$Infant.Mortality,method="jitter")
?swiss
pairs(swiss, panel = panel.smooth, main = "swiss data",
col = 3 + (swiss$Catholic > 50))
?hist
hist(swiss$Fertility)
hist(swiss$Education)
mean(swiss$Education)
summary(swiss$Education)
hist(swiss$Education, breaks = 5)
hist(swiss$Education, breaks = 5)
hist(swiss$Education, breaks = 4)
hist(swiss$Education,breaks=2)
hist(swiss$Education,breaks=2)
hist(swiss$Education,breaks=10)
?hist
?swiss
hist(swiss$Education,breaks=10, main='Swiss education histogram',
xlab='% Infant.Mortality   live births who live less than 1 year')
hist(swiss$Education)
?swiss
stripchart(swiss$Fertility)
stripchart(swiss$Fertility,method="jitter")
stripchart(swiss$Fertility,method="jitter", main='Fertility in the swiss database',
xlab='Fertility in LG'
)
hist(swiss$Education)
summary(swiss$Education)
mean(swiss$Education)
hist(swiss$Education,breaks=10, main='Swiss education histogram',
xlab='% Infant.Mortality   live births who live less than 1 year')
boxplot(swiss$Education)
boxplot(swiss$Fertility, main='Fertility in the swiss database',
xlab='Fertility in LG')
plot(swiss$Fertility, swiss$Education)
cor(swiss$Fertility, swiss$Education)
swiss
plot(swiss$Fertility, swiss$Infant.Mortality)
cor(swiss$Fertility, swiss$Infant.Mortality)
plot(swiss$Fertility, swiss$Agriculture)
cor(swiss$Fertility, swiss$Agriculture)
plot(swiss$Fertility, swiss$Examination)
cor(swiss$Fertility, swiss$Examination)
plot(swiss$Fertility, swiss$Education)
cor(swiss$Fertility, swiss$Education)
plot(swiss$Fertility, swiss$Catholic)
cor(swiss$Fertility, swiss$Catholic)
plot(swiss$Fertility, swiss$Infant.Mortality)
cor(swiss$Fertility, swiss$Infant.Mortality)
qqnorm(swiss$Fertility)
??qqnorm
qqnorm(swiss$Fertility)
qqline(swiss$Fertility)
?qqnorm
plot(swiss$Fertility, swiss$Examination)
cor(swiss$Fertility, swiss$Examination)
temp <- swiss[swiss$Education > 0.75, swiss$Examination > 0.75]
temp <- swiss[swiss$Education > 0.75, swiss$Examination > 0.75,]
temp <- swiss[swiss$Education > 0.75 & swiss$Examination > 0.75,]
summary(temp$fertility)
summary(temp)
?discretize
discretize
library(arules)
install.packages(arules)
cut(swiss$Fertility, c(0,0.25,0.5,0.75,1))
cut(swiss$Education, c(0,0.25,0.5,0.75,1))
swiss$Education
cut(swiss$Education, c(0,25,50,75,100))
swiss$EducationCategorical <- cut(swiss$Education, c(0,25,50,75,100))
swiss$EducationCategorical
swiss[swiss$EducationCategorical  == "(75,100]"]
swiss$EducationCategorical[1]
swiss$EducationCategorical == "(75,100]"
swiss$EducationCategorical == 1
fileInput<- "C:\Users\rmongemo\Desktop\SampleEDWData\channel ops 201409.csv"
dataFrame <- read.csv(fileInput)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201409.csv"
dataFrame <- read.csv(fileInput)
?read.csv
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = "~", quote = "", header=T)
View(frame)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = "~", quote = "", header=T)
frame <- read.csv(fileInput, sep = "~", header=T)
quote = ""
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = ",", quote = "", header=T)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = ",", quote = "", header=T)
fileInput<- "C:/Users/rmongemo/Desktop/SampleEDWData/channel ops 201501 Germany from old query.csv"
frame <- read.csv(fileInput, sep = ",", quote = "\"", header=T)
data()
data(airquality)
data(airquality)
airquality
plot(Ozone~Solor.R, data=airquality)
plot(Ozone~Solar.R, data=airquality)
2+2
data(mtcars)
n <- length(mtcars$mpg)
alpha <- 0.05
fit <- lm(mpg ~ am, data = mtcars)
coef(summary(fit))
sat<- read.csv("Sat.csv")
library(dplyr)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
set.seed(125)
set.seed(125)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
inTraining <- createDataPartition(y=spam$Case,list=FALSE)
inTraining <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
set.seed(125)
inTraining <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTraining
]
testing  <- segmentationOriginal[-inTraining]
modFit <- train(Case ~ .,method="rpart",data=training)
modFit <- train(Case ~ .,method="rpart",data=training)
modFit <- train(Case ~ .,method="rpart",data=training)
library(caret)
modFit <- train(Case ~ .,method="rpart",data=training)
?train
modFit <- train(Case ~ . ,method="rpart",data=training)
modFit <- train(Case ~ . ,method="rpart", data=training)
modFit <- train(form= Case ~ . ,method="rpart", data=training)
data(iris);
library(ggplot2)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species ~ .,method="rpart",data=training)
data(segmentationOriginal)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
set.seed(125)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=training)
prediction <- predict(modFit,newdata=testing)
print(modFit)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,      main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
View(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Class,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Class ~ .,method="rpart",data=training)
prediction <- predict(modFit,newdata=testing)
plot(modFit$finalModel, uniform=TRUE,      main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
4.726e+04
library(dplyr)
training <- filter(segmentationOriginal, Case == "Train")
training <- filter(segmentationOriginal, Case == "Train")
testing <- filter(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ .,method="rpart",data=training)
library(rpart)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(rpart.plot)
install.packages(rpart.plot)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
View(olive)
modFit <- train(Area ~ .,method="rpart",data=olive)
library(rattle)
library(rpart.plot)
library(caret)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit,newdata=newdata)
View(olive)
library(ElemStatLearn)
install.packages("ElemStatLearn")
?train
library(ElemStatLearn)
library(rattle)
library(rpart.plot)
library(caret)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modFit <- train(Area ~ .,method="glm",data=train, family = "binomial")
View(SAheart)
str(SAheart)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea+ ldl,method="glm",data=trainSA, family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predictResult <- predict(modFit,newdata=testSA)
predictTrain <- predict(modFit,newdata=trainSA)
predictTest <- predict(modFit,newdata=testSA)
missClass(trainSA$chd, predictTrain)
missClass(testSa$chd, predictTest) $ 0.27
missClass(testSa$chd, predictTest)
missClass(testSA$chd, predictTest) # 0.27
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
vowel.test
View(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
?varImp
varImp(modFit)
install.packages("twitteR")
install.packages("streamR")
install.packages("ROAuth")
install.package("htmltools")
install.packages("htmltools")
install.packages("caTools")
install.packages("rmarkdown")
library(twitteR)
library(RCurl)
library(base64enc)
library(httr)
library(base)
load(file = "twitterApiInformationAndProxy.rda")
library(syuzhet)
s_v <- get_sentences("I begin this story with a neutral statement.
Now I add a statement about how much I despise cats.
I am allergic to them. Basically this is a very silly test.")
library(rJava)
library(rJava)
library(rJava)
surface4PlotEmotion <- combined %>% filter(source == "surface4") %>% ggplot(aes(x=created, y=..count..))+ geom_line()
library(twitteR)
library(RCurl)
library(base64enc)
library(httr)
library(tm)
library(ggplot2)
library(SnowballC)
library(reshape2)
library(sentiment)
library(fpc)
library(cluster)
library(dplyr)
library(tm)
source("GetTweets.R")
source("BuildCorpus.R")
source("keywordChart.R")
source("Clusters.R")
source("Sentiment.R")
setwd("C:/rafamonge/Twitter/R")
combined %>% filter(source == "surface4") %>% ggplot(aes(x=created, y=..count..))+ geom_line()
library(twitteR)
library(RCurl)
library(base64enc)
library(httr)
library(tm)
library(ggplot2)
library(SnowballC)
library(reshape2)
library(sentiment)
library(fpc)
library(cluster)
library(dplyr)
library(tm)
source("GetTweets.R")
source("BuildCorpus.R")
source("keywordChart.R")
source("Clusters.R")
source("Sentiment.R")
combined
combined <- readRDS("TwitterData/combined.rda")
combined %>% filter(source == "surface4") %>% ggplot(aes(x=created, y=..count..))+ geom_line()
combined %>% filter(source == "surface4") %>% ggplot(aes(x=created, y=..count..))
combined %>% filter(source == "surface4") %>% ggplot(aes(x=created, y=..count..)) + geom_line()
library(dplyr)
View(combined)
combined %>% group_by(source)  %>%
summarise(count = n())
countBySource <- combined %>% group_by(source,created)  %>%
summarise(count = n())
countBySource
?day
class(combined$created)
combined$created[1]
names(combined$created[1])
class(combined$created[1])
combined$created[1]$sec
as.Date(combined$created[1]$sec)
as.Date(combined$created[1])
class(as.Date(combined$created[1]))
combinedMod$date <- as.Date(combinedMod$created)
combinedMod <- combined
combinedMod$date <- as.Date(combinedMod$created)
countBySource <- combined %>% group_by(source,date)  %>%
summarise(count = n())
countBySource <- combinedMod %>% group_by(source,date)  %>%
summarise(count = n())
countBySource
combinedMod %>% group_by(source,date,countBySourceDate = n())
countBySource <- combinedMod %>% group_by(source,date,countBySourceDate = n())
countBySource[1,]
countBySource[2,]
View(countBySource[1:5])
countBySource <- combinedMod %>% group_by(source,date,countBySourceDate = n())
View(countBySource[1:5])
combinedMod %>% group_by(source, cnt = sum())
countBySource <- combinedMod %>% group_by(source, cnt = sum())
View(countBySource)
source('C:/rafamonge/Twitter/R/Surface4.R', echo=TRUE)
countBySource <- combinedMod %>% group_by(source, cnt = n())
View(countBySource)
countBySource <- combinedMod %>% group_by(source) %>%  summarize(cnt = n())
View(countBySource)
library(Lahman)
install.packages(Lahman)
install.packages("Lahman")
library("Lahman")
?tbl_df
countBySource <- combinedMod %>% group_by(source) %>%  mutate(cnt = n())
View(countBySource)
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(cnt = n())
View(countBySource)
combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity)
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity) %>% summarize(pct = 100* n()/ countBySourceDate)
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity) %>% summarize(pct = n())
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity) %>% summarize(pct = n()/countBySourceDate )
max
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity) %>% summarize(pct = n()/max(countBySourceDate) )
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity) %>% summarize(pct = 100*n()/max(countBySourceDate) )
countBySource
countBySource <- combinedMod %>% group_by(source, date) %>%  mutate(countBySourceDate = n())  %>% group_by(source, date, polarity) %>% summarize(pct = 100*n()/max(countBySourceDate) ) %>% arrange(source, date, polarity
)
countBySource
countBySource %>% filter(polarity="positve")
countBySource %>% filter(polarity=="positve")
View(countBySource %>% filter(polarity=="positve"))
class(countBySource$polarity)
View(countBySource %>% filter(polarity=="positive"))
countBySource %>% filter(polarity=="positive") %>% ggplot(aes(x=date, y=pct)) %>% geom_line()
positive <- countBySource %>% filter(polarity=="positive")
ggplot(positive, aes(x=date, y=pct)) %>% geom_line()
ggplot(positive, aes(x=date, y=pct)) + geom_line()
ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line()
ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line() + geom_smooth()
ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line()
positivePlot <- ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line()
positivePlot <- ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line() + ylab("Percentage of positive of tweets per day") + xlab("Date")
positivePlot
positivePlot <- ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line() + ylab("% of positive of tweets per day") + xlab("Date") + ggtitle("Sentiment over time")
ggsave("plots/positivePlotOverTime.png", positivePlotOverTime, width = 10, height = 4)
positivePlotOverTime <- ggplot(positive, aes(x=date, y=pct, colour=source)) + geom_line() + ylab("% of positive of tweets per day") + xlab("Date") + ggtitle("Sentiment over time")
ggsave("plots/positivePlotOverTime.png", positivePlotOverTime, width = 10, height = 4)
